{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d771f08-9e37-4261-b9dc-20828c2c79c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13dfc5cc-af82-40ea-806c-09cc13d020e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_cols = ['user_id', 'movie_id', 'rating', 'ts']\n",
    "data = []\n",
    "with open('data/ml-100k/u.data', 'r') as f:\n",
    "    while True:\n",
    "        l = f.readline() \n",
    "        if not l:\n",
    "            break\n",
    "        res = l[:-1].split('\\t')\n",
    "        info_d = {}\n",
    "        for i in range(len(data_cols)):\n",
    "            info_d[data_cols[i]] = res[i]\n",
    "        data.append(info_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c478e719-53a0-4cb3-94cf-cf044d3d596a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "item_cols = ['movie_id', 'movie_title', 'release_date', 'video_release_date', 'IMDb_url', 'unknown', 'Action', \n",
    "'Adventure', 'Animation', \"Children's\", \"Comedy\", \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\",\n",
    "\"Horror\", \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"]\n",
    "items = []\n",
    "with open('data/ml-100k/u.item', 'r', encoding='ISO-8859-1') as f:\n",
    "    while True:\n",
    "        l = f.readline()\n",
    "        if not l:\n",
    "            break\n",
    "        res = l[:-1].split('|')\n",
    "        info_d = {}\n",
    "        for i in range(len(item_cols)):\n",
    "            info_d[item_cols[i]] = res[i]\n",
    "        items.append(info_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5ecc8d0-bf1e-4f96-ad4b-73e65c8e3c53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_cols = ['user_id', 'age', 'gender', 'occupation', 'zipcode']\n",
    "users = []\n",
    "with open('data/ml-100k/u.user', 'r', encoding='ISO-8859-1') as f:\n",
    "    while True:\n",
    "        l = f.readline()\n",
    "        if not l:\n",
    "            break\n",
    "        res = l[:-1].split('|')\n",
    "        info_d = {}\n",
    "        for i in range(len(user_cols)):\n",
    "            info_d[user_cols[i]] = res[i]\n",
    "        users.append(info_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc323c95-df53-4037-a55b-45496a674b9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_items = pd.DataFrame(items)\n",
    "df_users = pd.DataFrame(users)\n",
    "df_data = pd.DataFrame(data)\n",
    "df_data['user_id'] = df_data['user_id'].astype(int)\n",
    "df_data['movie_id'] = df_data['movie_id'].astype(int)\n",
    "df_data['rating'] = df_data['rating'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34716749-4666-499f-9169-60de7a362cd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df_data, random_state=1, test_size=0.4)\n",
    "df_val = df_test[:len(df_test)//4]\n",
    "df_test = df_test[len(df_test)//4:]\n",
    "\n",
    "X_train = np.array(df_train[['user_id', 'movie_id']])\n",
    "y_train = np.array(df_train['rating'])\n",
    "X_val = np.array(df_val[['user_id', 'movie_id']])\n",
    "y_val = np.array(df_val['rating'])\n",
    "X_test = np.array(df_test[['user_id', 'movie_id']])\n",
    "y_test = np.array(df_test['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e065e9eb-008b-4ce2-92f4-a79c665ffb50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_users = len(df_users)\n",
    "n_items = len(df_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94496fb-3441-444f-920c-877dc704df96",
   "metadata": {
    "tags": []
   },
   "source": [
    "## prepare batch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d64ce49d-7fd8-4abf-b4b0-53eff77db318",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prep_batch_dataset(X, y, batch_size):\n",
    "    tensorX = torch.tensor(X)\n",
    "    tensory = torch.tensor(y)\n",
    "    dataset = TensorDataset(tensorX, tensory)\n",
    "    dl = DataLoader(dataset, batch_size)\n",
    "    return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60b0b542-e445-487e-aeb6-85ffd2a27602",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "dl_train = prep_batch_dataset(X_train, y_train, batch_size)\n",
    "dl_val = prep_batch_dataset(X_val, y_val, batch_size)\n",
    "dl_test = prep_batch_dataset(X_test, y_test, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac96993-d4d3-452f-8a66-4c2a14f428d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "07514967-2572-46a2-b5a1-82ef16c99bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, num_users, num_items, dim):\n",
    "        super().__init__()\n",
    "        self.n_users = num_users\n",
    "        self.n_items = num_items\n",
    "        self.user_embedding = nn.Embedding(self.n_users, dim, sparse=True)\n",
    "        self.item_embedding = nn.Embedding(self.n_items, dim, sparse=True)\n",
    "    \n",
    "    def forward(self, user, item):\n",
    "        return (self.user_embedding(user) * self.item_embedding(item)).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "752bd329-d97d-475b-8f55-3a9b6c295a09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.named_parameters at 0x2b0da9b30>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "95542c95-9892-4e18-94eb-9652838e5f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MatrixFactorization(n_users+1, n_items+1, dim=100)\n",
    "alpha = 1\n",
    "loss_fn = nn.MSELoss()\n",
    "opt = torch.optim.SparseAdam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0c3a9a47-ee77-4676-8b35-1bd4f3c4a887",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Train loss = 130.3518, Val loss = 128.7564, Test loss = 128.9979\n",
      "Iteration 10, Train loss = 83.0928, Val loss = 107.5646, Test loss = 107.8861\n",
      "Iteration 20, Train loss = 57.3953, Val loss = 94.0227, Test loss = 94.4044\n",
      "Iteration 30, Train loss = 42.3057, Val loss = 84.5172, Test loss = 84.9488\n",
      "Iteration 40, Train loss = 32.8826, Val loss = 77.1413, Test loss = 77.6146\n",
      "Iteration 50, Train loss = 26.6466, Val loss = 70.773, Test loss = 71.2716\n",
      "Iteration 60, Train loss = 22.3334, Val loss = 64.8159, Test loss = 65.3105\n",
      "Iteration 70, Train loss = 19.314, Val loss = 59.1334, Test loss = 59.5957\n",
      "Iteration 80, Train loss = 17.1699, Val loss = 53.7763, Test loss = 54.1826\n",
      "Iteration 90, Train loss = 15.5444, Val loss = 48.7068, Test loss = 49.0417\n",
      "Iteration 100, Train loss = 14.1831, Val loss = 43.7918, Test loss = 44.0498\n",
      "Iteration 110, Train loss = 12.9376, Val loss = 38.9127, Test loss = 39.097\n",
      "Iteration 120, Train loss = 11.7245, Val loss = 34.0155, Test loss = 34.1359\n",
      "Iteration 130, Train loss = 10.5221, Val loss = 29.1339, Test loss = 29.2082\n",
      "Iteration 140, Train loss = 9.3402, Val loss = 24.3688, Test loss = 24.4161\n",
      "Iteration 150, Train loss = 8.2103, Val loss = 19.876, Test loss = 19.9072\n",
      "Iteration 160, Train loss = 7.1731, Val loss = 15.8318, Test loss = 15.8537\n",
      "Iteration 170, Train loss = 6.2654, Val loss = 12.3982, Test loss = 12.412\n",
      "Iteration 180, Train loss = 5.5101, Val loss = 9.676, Test loss = 9.6846\n",
      "Iteration 190, Train loss = 4.9135, Val loss = 7.6785, Test loss = 7.6846\n",
      "Iteration 200, Train loss = 4.4705, Val loss = 6.3257, Test loss = 6.3297\n",
      "Iteration 210, Train loss = 4.1652, Val loss = 5.4732, Test loss = 5.4751\n",
      "Iteration 220, Train loss = 3.9702, Val loss = 4.9621, Test loss = 4.9621\n",
      "Iteration 230, Train loss = 3.8535, Val loss = 4.6628, Test loss = 4.6615\n",
      "Iteration 240, Train loss = 3.7867, Val loss = 4.4875, Test loss = 4.4855\n",
      "Iteration 250, Train loss = 3.7491, Val loss = 4.3832, Test loss = 4.381\n",
      "Iteration 260, Train loss = 3.7276, Val loss = 4.3199, Test loss = 4.3177\n",
      "Iteration 270, Train loss = 3.7149, Val loss = 4.2805, Test loss = 4.2786\n",
      "Iteration 280, Train loss = 3.7071, Val loss = 4.2555, Test loss = 4.2537\n",
      "Iteration 290, Train loss = 3.702, Val loss = 4.2392, Test loss = 4.2376\n",
      "Iteration 300, Train loss = 3.6985, Val loss = 4.2284, Test loss = 4.227\n",
      "Iteration 310, Train loss = 3.6961, Val loss = 4.2211, Test loss = 4.2198\n",
      "Iteration 320, Train loss = 3.6943, Val loss = 4.2161, Test loss = 4.2149\n",
      "Iteration 330, Train loss = 3.693, Val loss = 4.2127, Test loss = 4.2115\n",
      "Iteration 340, Train loss = 3.692, Val loss = 4.2103, Test loss = 4.2091\n",
      "Iteration 350, Train loss = 3.6912, Val loss = 4.2085, Test loss = 4.2074\n",
      "Iteration 360, Train loss = 3.6905, Val loss = 4.2073, Test loss = 4.2062\n",
      "Iteration 370, Train loss = 3.69, Val loss = 4.2065, Test loss = 4.2054\n",
      "Iteration 380, Train loss = 3.6896, Val loss = 4.2058, Test loss = 4.2048\n",
      "Iteration 390, Train loss = 3.6893, Val loss = 4.2054, Test loss = 4.2043\n",
      "Iteration 400, Train loss = 3.689, Val loss = 4.2051, Test loss = 4.204\n",
      "Iteration 410, Train loss = 3.6887, Val loss = 4.2048, Test loss = 4.2038\n",
      "Iteration 420, Train loss = 3.6885, Val loss = 4.2047, Test loss = 4.2037\n",
      "Iteration 430, Train loss = 3.6884, Val loss = 4.2046, Test loss = 4.2036\n",
      "Iteration 440, Train loss = 3.6882, Val loss = 4.2045, Test loss = 4.2035\n",
      "Iteration 450, Train loss = 3.6881, Val loss = 4.2044, Test loss = 4.2034\n",
      "Iteration 460, Train loss = 3.688, Val loss = 4.2044, Test loss = 4.2034\n",
      "Iteration 470, Train loss = 3.6879, Val loss = 4.2043, Test loss = 4.2034\n",
      "Iteration 480, Train loss = 3.6878, Val loss = 4.2043, Test loss = 4.2034\n",
      "Iteration 490, Train loss = 3.6877, Val loss = 4.2043, Test loss = 4.2034\n",
      "Iteration 500, Train loss = 3.6876, Val loss = 4.2043, Test loss = 4.2034\n",
      "Iteration 510, Train loss = 3.6876, Val loss = 4.2042, Test loss = 4.2034\n",
      "Iteration 520, Train loss = 3.6875, Val loss = 4.2042, Test loss = 4.2034\n",
      "Iteration 530, Train loss = 3.6875, Val loss = 4.2042, Test loss = 4.2034\n",
      "Iteration 540, Train loss = 3.6874, Val loss = 4.2042, Test loss = 4.2034\n",
      "Iteration 550, Train loss = 3.6874, Val loss = 4.2042, Test loss = 4.2034\n",
      "Iteration 560, Train loss = 3.6873, Val loss = 4.2041, Test loss = 4.2033\n",
      "Iteration 570, Train loss = 3.6873, Val loss = 4.2041, Test loss = 4.2033\n",
      "Iteration 580, Train loss = 3.6873, Val loss = 4.2041, Test loss = 4.2033\n",
      "Iteration 590, Train loss = 3.6872, Val loss = 4.2041, Test loss = 4.2033\n",
      "Iteration 600, Train loss = 3.6872, Val loss = 4.204, Test loss = 4.2033\n",
      "Iteration 610, Train loss = 3.6872, Val loss = 4.204, Test loss = 4.2033\n",
      "Iteration 620, Train loss = 3.6871, Val loss = 4.204, Test loss = 4.2033\n",
      "Iteration 630, Train loss = 3.6871, Val loss = 4.2039, Test loss = 4.2033\n",
      "Iteration 640, Train loss = 3.6871, Val loss = 4.2039, Test loss = 4.2033\n",
      "Iteration 650, Train loss = 3.6871, Val loss = 4.2039, Test loss = 4.2033\n",
      "Iteration 660, Train loss = 3.687, Val loss = 4.2039, Test loss = 4.2033\n",
      "Iteration 670, Train loss = 3.687, Val loss = 4.2038, Test loss = 4.2032\n",
      "Iteration 680, Train loss = 3.687, Val loss = 4.2038, Test loss = 4.2032\n",
      "Iteration 690, Train loss = 3.687, Val loss = 4.2038, Test loss = 4.2032\n",
      "Iteration 700, Train loss = 3.687, Val loss = 4.2037, Test loss = 4.2032\n",
      "Iteration 710, Train loss = 3.6869, Val loss = 4.2037, Test loss = 4.2032\n",
      "Iteration 720, Train loss = 3.6869, Val loss = 4.2037, Test loss = 4.2032\n",
      "Iteration 730, Train loss = 3.6869, Val loss = 4.2036, Test loss = 4.2031\n",
      "Iteration 740, Train loss = 3.6869, Val loss = 4.2036, Test loss = 4.2031\n",
      "Iteration 750, Train loss = 3.6869, Val loss = 4.2036, Test loss = 4.2031\n",
      "Iteration 760, Train loss = 3.6868, Val loss = 4.2035, Test loss = 4.2031\n",
      "Iteration 770, Train loss = 3.6868, Val loss = 4.2035, Test loss = 4.2031\n",
      "Iteration 780, Train loss = 3.6868, Val loss = 4.2035, Test loss = 4.203\n",
      "Iteration 790, Train loss = 3.6868, Val loss = 4.2034, Test loss = 4.203\n",
      "Iteration 800, Train loss = 3.6868, Val loss = 4.2034, Test loss = 4.203\n",
      "Iteration 810, Train loss = 3.6868, Val loss = 4.2034, Test loss = 4.203\n",
      "Iteration 820, Train loss = 3.6867, Val loss = 4.2033, Test loss = 4.203\n",
      "Iteration 830, Train loss = 3.6867, Val loss = 4.2033, Test loss = 4.2029\n",
      "Iteration 840, Train loss = 3.6867, Val loss = 4.2033, Test loss = 4.2029\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m     batch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m alpha \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(model\u001b[38;5;241m.\u001b[39mitem_embedding(torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mrange\u001b[39m(model\u001b[38;5;241m.\u001b[39mn_items))), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     15\u001b[0m     batch_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 16\u001b[0m     \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     epoch_losses_train\u001b[38;5;241m.\u001b[39mappend(batch_loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     18\u001b[0m losses_train\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39marray(epoch_losses_train)\u001b[38;5;241m.\u001b[39mmean())\n",
      "File \u001b[0;32m~/personal/repos/playground/env/lib/python3.8/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/personal/repos/playground/env/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/personal/repos/playground/env/lib/python3.8/site-packages/torch/optim/sparse_adam.py:87\u001b[0m, in \u001b[0;36mSparseAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;66;03m# record the step after step update\u001b[39;00m\n\u001b[1;32m     85\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 87\u001b[0m     \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse_adam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m                  \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/personal/repos/playground/env/lib/python3.8/site-packages/torch/optim/_functional.py:72\u001b[0m, in \u001b[0;36msparse_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, state_steps, eps, beta1, beta2, lr, maximize)\u001b[0m\n\u001b[1;32m     70\u001b[0m numer \u001b[38;5;241m=\u001b[39m exp_avg_update_values\u001b[38;5;241m.\u001b[39madd_(old_exp_avg_values)\n\u001b[1;32m     71\u001b[0m exp_avg_sq_update_values\u001b[38;5;241m.\u001b[39madd_(old_exp_avg_sq_values)\n\u001b[0;32m---> 72\u001b[0m denom \u001b[38;5;241m=\u001b[39m \u001b[43mexp_avg_sq_update_values\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m exp_avg_update_values, exp_avg_sq_update_values\n\u001b[1;32m     75\u001b[0m bias_correction1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m step\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "losses_train = []\n",
    "losses_val = []\n",
    "losses_test = []\n",
    "alpha = 1\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    epoch_losses_train = []\n",
    "    for bi, (x,y) in enumerate(dl_train):\n",
    "        opt.zero_grad()\n",
    "        y_pred = model(x[:,0],x[:,1])\n",
    "        batch_loss = loss_fn(y_pred, y)\n",
    "        mse = batch_loss\n",
    "        batch_loss += alpha * torch.norm(model.user_embedding(torch.tensor(range(model.n_users))), dim=1).mean() \n",
    "        batch_loss += alpha * torch.norm(model.item_embedding(torch.tensor(range(model.n_items))), dim=1).mean()\n",
    "        batch_loss.backward()\n",
    "        opt.step()\n",
    "        epoch_losses_train.append(batch_loss.item())\n",
    "    losses_train.append(np.array(epoch_losses_train).mean())\n",
    "\n",
    "    if i%10==0:\n",
    "        epoch_losses_val = []\n",
    "        epoch_losses_test = []\n",
    "        for bi, (x,y) in enumerate(dl_val):\n",
    "            y_pred = model(x[:,0], x[:,1])\n",
    "            batch_loss = loss_fn(y_pred, y) \n",
    "            batch_loss += alpha * torch.norm(model.user_embedding(torch.tensor(range(model.n_users))), dim=1).mean() \n",
    "            batch_loss += alpha * torch.norm(model.item_embedding(torch.tensor(range(model.n_items))), dim=1).mean()\n",
    "            epoch_losses_val.append(batch_loss.item())\n",
    "        losses_val.append(np.array(epoch_losses_val).mean())\n",
    "\n",
    "        for bi, (x,y) in enumerate(dl_test):\n",
    "            y_pred = model(x[:,0], x[:,1])\n",
    "            batch_loss = loss_fn(y_pred, y)\n",
    "            batch_loss += alpha * torch.norm(model.user_embedding(torch.tensor(range(model.n_users))), dim=1).mean() \n",
    "            batch_loss += alpha * torch.norm(model.item_embedding(torch.tensor(range(model.n_items))), dim=1).mean()\n",
    "            epoch_losses_test.append(batch_loss.item())\n",
    "        losses_test.append(np.array(epoch_losses_test).mean())\n",
    "        \n",
    "        print(f'Iteration {i}, Train loss = {round(losses_train[-1],4)}, Val loss = {round(losses_val[-1],4)}, Test loss = {round(losses_test[-1],4)}')\n",
    "    \n",
    "        if len(losses_val)>1 and losses_val[-1] - losses_val[-2] > 0:\n",
    "            print(f\"Early stopped at iteration {i}\")\n",
    "            break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e268956-5913-4e05-b1f7-72715a839962",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test loss = 4.2029"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6292cf09-f852-4b60-b8c9-6b5abc931499",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b86c1d90>]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(losses_train[:400], color='b')\n",
    "plt.plot(np.arange(0,400,10), losses_val[:40], color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5fa55427-c63e-4b93-bdde-8b214be9497c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37733333333333335"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((torch.round(.detach().numpy()==y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ac776652-788e-4105-86ca-003158068454",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2603, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model(torch.tensor(X_test)[:,0], torch.tensor(X_test)[:,1])-torch.tensor(y_test)).pow(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767af1e4-28ca-481a-ad40-e490e39e76a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a08a08d-f50d-44d1-8fda-0e6c8129c0ee",
   "metadata": {},
   "source": [
    "# Include other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57696c54-7c23-4170-82cf-a57c7aaf20d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ca2e8dc-c1c0-4fef-a721-a53c6e8fa978",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_users['user_id'] = df_users['user_id'].astype(int)\n",
    "df_users['age'] = df_users['age'].astype(int)\n",
    "df_users['zipcode'] = df_users['zipcode'].map(lambda x: int(x) if x.isdigit() else None)\n",
    "df_users['zipcode'].fillna(df_users['zipcode'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75370fce-c485-47d2-b4e6-d0d145389cdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l = list(df_users['occupation'].value_counts().index)\n",
    "for o in l:\n",
    "    df_users[o] = 0\n",
    "    df_users.loc[df_users['occupation']==o, o] = 1\n",
    "    \n",
    "l = list(df_users['gender'].value_counts().index)\n",
    "for g in l:\n",
    "    df_users[g] = 0\n",
    "    df_users.loc[df_users['gender']==g, g] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5eeeea8-1346-477e-8585-af6ed2ddb644",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_scaler = MinMaxScaler()\n",
    "df_users[['age_trans', 'zipcode_trans']] = user_scaler.fit_transform(df_users[['age', 'zipcode']])\n",
    "df_users.drop(columns=['age', 'gender', 'occupation', 'zipcode'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "288aac86-05da-4d95-9f91-6568d13af5bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in list(df_users.columns)[1:]:\n",
    "    df_users[col] = df_users[col].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a62d089b-b63d-4d90-8a02-80d7473275aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_items['movie_id'] = df_items['movie_id'].astype(int)\n",
    "df_items[item_cols[5:]] = df_items[item_cols[5:]].astype(int)\n",
    "df_items.drop(columns=item_cols[1:5], inplace=True)\n",
    "for col in list(df_items.columns)[1:]:\n",
    "    df_items[col] = df_items[col].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bed9c171-9edc-4069-a52b-a3623d1446d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = df_train.merge(df_users, on='user_id').merge(df_items, on='movie_id')\n",
    "df_val = df_val.merge(df_users, on='user_id').merge(df_items, on='movie_id')\n",
    "df_test = df_test.merge(df_users, on='user_id').merge(df_items, on='movie_id')\n",
    "\n",
    "f_list = list(df_train.columns[4:])\n",
    "z_train = np.array(df_train[f_list])\n",
    "z_val = np.array(df_val[f_list])\n",
    "z_test = np.array(df_test[f_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e50db9c-3a41-4df8-b66a-ef813026bc2c",
   "metadata": {},
   "source": [
    "## prepare batch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85298d79-3f62-40aa-970c-94a9e4faca50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prep_batch_dataset2(X, z, y, batch_size):\n",
    "    dataset2 = TensorDataset(torch.tensor(X), torch.tensor(z), torch.tensor(y.reshape((-1,1))))\n",
    "    return DataLoader(dataset2, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d479ddc-9dea-4878-8dac-e1b67c462039",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "dl2_train = prep_batch_dataset2(X_train, z_train, y_train, batch_size)\n",
    "dl2_val = prep_batch_dataset2(X_val, z_val, y_val, batch_size)\n",
    "dl2_test = prep_batch_dataset2(X_test, z_test, y_test, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a62b72-8f4a-4b92-97d2-5b80840bb5c1",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea38b77f-7223-45c0-85b1-0005edd1f1f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, n_users, n_items, embedding_dims, hidden_dims, dropout_prob):\n",
    "        def init_weights(m):\n",
    "            if type(m) in [nn.Linear, nn.LazyLinear]:\n",
    "                torch.nn.init.xavier_uniform(m.weight)\n",
    "                m.bias.data.fill_(0.01)\n",
    "            \n",
    "        super().__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.user_embedding = nn.Embedding(self.n_users, embedding_dims['user'])\n",
    "        self.item_embedding = nn.Embedding(self.n_items, embedding_dims['item'])\n",
    "        self.dense_layers = []\n",
    "        for i in range(len(hidden_dims)):\n",
    "            self.dense_layers.append((f\"linear{i}\", nn.LazyLinear(hidden_dims[i])))\n",
    "            self.dense_layers.append((f\"BatchNorm{i}\", nn.LazyBatchNorm1d()))\n",
    "            self.dense_layers.append((f\"Relu{i}\", nn.ReLU()))\n",
    "            self.dense_layers.append((f\"Dropout{i}\", nn.Dropout(dropout_prob)))\n",
    "        self.dense_layers = nn.Sequential(OrderedDict(self.dense_layers))\n",
    "        # self.dense_layers.apply(init_weights)\n",
    "        self.final_layer = nn.LazyLinear(1)\n",
    "        \n",
    "    \n",
    "        \n",
    "    def forward(self, user, item, z):\n",
    "        out = torch.concat((self.user_embedding(user), self.item_embedding(item), z), dim=1)\n",
    "        out = self.dense_layers(out)\n",
    "        out = self.final_layer(out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c247b7d4-04a2-49a1-adc3-8c056f66f6ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2 = DNN(n_users+1, n_items+1, {'user': 50, 'item': 50}, [128, 64, 64, 16], 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a965666-f093-4565-bb06-2571a7f521d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "opt = torch.optim.Adam(model2.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eb8dc27d-9d67-4568-906b-3cca90d4ac5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alpha = 0.5\n",
    "def train(train_dl, val_dl, test_dl, n_epochs, optimizer, print_every=10):\n",
    "    epoch_loss_train = []\n",
    "    epoch_mse_train = []\n",
    "    epoch_mse_val = []\n",
    "    for i in range(n_epochs):\n",
    "        batch_loss_train = []\n",
    "        batch_mse_train = []\n",
    "        for _, (x,z,y) in enumerate(train_dl):\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model2(x[:,0], x[:,1], z)\n",
    "            mse_loss = loss_fn(y_pred, y) \n",
    "            loss = loss_fn(y_pred, y) \n",
    "            loss += alpha*torch.norm(model2.user_embedding(torch.tensor(range(model2.n_users))), dim=1).mean()\n",
    "            loss += alpha*torch.norm(model2.item_embedding(torch.tensor(range(model2.n_items))), dim=1).mean() \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            batch_loss_train.append(loss.item())\n",
    "            batch_mse_train.append(mse_loss.item())\n",
    "        epoch_loss_train.append(np.array(batch_loss_train).mean())\n",
    "        epoch_mse_train.append(np.array(batch_mse_train).mean())\n",
    "        \n",
    "        if i % print_every==0:\n",
    "            batch_mse_val = []\n",
    "            for _, (x,z,y) in enumerate(val_dl):\n",
    "                y_pred = model2(x[:,0], x[:,1], z)\n",
    "                mse_loss = loss_fn(y_pred, y)\n",
    "                batch_mse_val.append(mse_loss.item())\n",
    "            # print(batch_mse_train, batch_mse_val)\n",
    "            epoch_mse_val.append(np.array(batch_mse_val).mean())\n",
    "            print(f\"Iteration {i}, Train loss = {round(epoch_loss_train[-1],4)}, Train MSE = {round(epoch_mse_train[-1],4)}, Validation MSE = {round(epoch_mse_val[-1],4)}\")\n",
    "            if len(epoch_mse_val)>2 and epoch_mse_val[-1] - epoch_mse_val[-2] > 0.01:\n",
    "                print(f\"Early Stopped at iteration {i}, Validation loss increase.\")\n",
    "                break\n",
    "            \n",
    "    return epoch_loss_train, epoch_mse_train, epoch_mse_val\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "662c546c-dad9-484f-aece-e92aaa77a983",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Train loss = 2.0063, Train MSE = 0.8526, Validation MSE = 1.2027\n",
      "Iteration 10, Train loss = 1.7721, Train MSE = 0.8009, Validation MSE = 1.1997\n",
      "Iteration 20, Train loss = 1.5934, Train MSE = 0.7497, Validation MSE = 1.232\n",
      "Early Stopped at iteration 20, Validation loss increase.\n"
     ]
    }
   ],
   "source": [
    "loss_train, mse_train, mse_val = train(dl2_train, dl2_val, dl2_test, 1000, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cda3832e-4990-4fef-ac52-c87a59c263e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9757, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model2(torch.tensor(X_test)[:,0], torch.tensor(X_test)[:,1], torch.tensor(z_test))-torch.tensor(y_test)).pow(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a48f759-3815-4247-affc-0c927f1e4119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54690c56-3fda-4680-a92c-0336b00840de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
