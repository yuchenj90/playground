{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d786ba2-f798-4d77-b0e1-63f80f456ef6",
   "metadata": {},
   "source": [
    "### write code to implement backward propagation for cross-entropy loss, only need to support the following type of layers:\n",
    "- Linear layer with in_dim and out_dim\n",
    "- ReLU layer\n",
    "- Softmax layer\n",
    "\n",
    "Example: \n",
    "``` Python\n",
    "Input:\n",
    "    n_labels = 10\n",
    "    layers = ['relu', 'relu', 'softmax']\n",
    "    weights = [np.random.uniform(-0.01, 0.01, (128,64)), np.random.uniform(-0.01, 0.01, (64,16)), np.random.uniform(-0.01, 0.01, (16,10))]\n",
    "    \n",
    "    batch_size = 256\n",
    "    X_train = np.random.rand(batch_size,128)\n",
    "    y_train = np.random.randint(low=0,high=n_labels,size=batch_size)\n",
    "\n",
    "Output:\n",
    "    w_grad\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bc5a9a4b-a6ff-4040-bbfe-c2cbc0c6217b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class DNN:\n",
    "    def __init__(self, n_labels, layers, weights):\n",
    "        assert len(layers) == len(weights), \"Every linear layer must followed by a non-linear activation!\"\n",
    "        self.n_layers = len(layers)\n",
    "        self.n_labels = n_labels\n",
    "        self.layers = layers\n",
    "        self.weights = weights\n",
    "        self.eps = 1e-100\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # time complexity O(B*size(weights)), space complexity O(B*size(weights))\n",
    "        self.forward_values = []\n",
    "        for i in range(self.n_layers):\n",
    "            w = self.weights[i]\n",
    "            d = {'input': x}\n",
    "            x = x @ w\n",
    "            d['hidden'] = x\n",
    "            if self.layers[i] == 'relu':\n",
    "                x = np.maximum(x,0)\n",
    "            elif self.layers[i] == 'softmax':\n",
    "                # x = (np.exp(x).transpose()/np.exp(x).sum(axis=1)).transpose() # can cause overflow when x is large\n",
    "                x_max = x.max(axis=1).reshape(-1,1)\n",
    "                x = (np.exp(x-x_max).transpose()/np.exp(x-x_max).sum(axis=1)).transpose()\n",
    "            d['output'] = x\n",
    "            self.forward_values.append(d)\n",
    "        return x\n",
    "    \n",
    "    def CrossEntropyLoss(self, y_pred, y_true):\n",
    "        return -np.array([np.log(np.maximum(y_pred[i,y_true[i]], self.eps)) for i in range(len(y_true))]).mean()\n",
    "\n",
    "    def backward(self, y_true):\n",
    "        # time complexity O(B*size(weights)), space complexity O(B*size(weights))\n",
    "        self.grads = []\n",
    "        for m in range(self.n_layers-1, -1, -1):\n",
    "            d = {}\n",
    "            if len(self.grads)==0:\n",
    "                onehot_y = np.array([np.eye(self.n_labels)[y] for y in y_train])\n",
    "                d['grad_o'] = -onehot_y/(self.forward_values[-1]['output']+self.eps)/onehot_y.shape[0] # (B, n_labels)\n",
    "            else:\n",
    "                d['grad_o'] = self.grads[-1]['grad_h'] @ self.weights[m+1].transpose()  # (B, d_h^m) \n",
    "            if self.layers[m] == 'relu':\n",
    "                d['grad_h'] = (self.forward_values[m]['hidden']>0) * d['grad_o'] # (B, d_h^(m))\n",
    "            elif self.layers[m] == 'softmax':    \n",
    "                do_h = np.array([np.diag(row) for row in self.forward_values[m]['output']]) # (B, d_h^m, d_h^m)\n",
    "                do_h = do_h - self.forward_values[m]['output'][:,:,np.newaxis] * self.forward_values[m]['output'][:,np.newaxis,:] # (B, d_h^m, d_h^m)\n",
    "                d['grad_h'] = (d['grad_o'][:,np.newaxis,:] * do_h).sum(axis=-1) # (B, d_h^m)\n",
    "\n",
    "            d['grad_w'] = (self.forward_values[m]['input'][:,:,np.newaxis] * d['grad_h'][:,np.newaxis,:]).sum(axis=0)\n",
    "            # print(d['grad_w'].shape) # (d_h^(m-1), d_h^m)\n",
    "            self.grads.append(d)\n",
    "        return [self.grads[i]['grad_w'] for i in range(len(self.grads)-1,-1,-1)] \n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e972669-d5c3-426f-a082-ef82dfa2c5c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_labels = 10\n",
    "layers = ['relu', 'relu', 'softmax']\n",
    "weights = [np.random.uniform(-0.01, 0.01, (128,64)), np.random.uniform(-0.01, 0.01, (64,16)), np.random.uniform(-0.01, 0.01, (16,10))]\n",
    "\n",
    "model = DNN(n_labels, layers, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "11d6656b-882d-4d09-b10b-9395629432e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "X_train = np.random.rand(batch_size,128)\n",
    "y_train = np.random.randint(low=0,high=2,size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "95ab2884-bba4-48f6-8774-32de779c97a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.397387882778907e-05\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "delta = 1e-7\n",
    "l, d1, d2 = 0, 10, 5\n",
    "\n",
    "x = model.forward(X_train)\n",
    "loss = model.CrossEntropyLoss(x, y_train)\n",
    "w_grad = model.backward(y_train)\n",
    "\n",
    "model.weights[l][d1][d2] += delta\n",
    "x_new = model.forward(X_train)\n",
    "loss_new = model.CrossEntropyLoss(x_new, y_train)\n",
    "delta_w = (loss_new - loss)/delta \n",
    "\n",
    "assert delta_w!=0, \"pick another weight!\"\n",
    "print(np.abs((w_grad[l][d1][d2] - delta_w) / (w_grad[l][d1][d2] + delta_w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3857fbe1-870d-4f07-996d-11825058776d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_model(model, X_train, y_train, n_iter:int=100, lr: float=1e-2):\n",
    "    for i in range(n_iter):\n",
    "        x = model.forward(X_train)\n",
    "        loss = model.CrossEntropyLoss(x, y_train)\n",
    "        w_grad = model.backward(y_train)\n",
    "        for k in range(model.n_layers):\n",
    "            model.weights[k] -= lr * w_grad[k]\n",
    "        print(f'Iteration {i+1}: loss={loss}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5811147f-b103-4309-91bb-7e66a5b7275a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: loss=2.3020734511656165\n",
      "Iteration 2: loss=2.3020424474294456\n",
      "Iteration 3: loss=2.3020090054559335\n",
      "Iteration 4: loss=2.301972875590674\n",
      "Iteration 5: loss=2.301933783964392\n",
      "Iteration 6: loss=2.3018914225619413\n",
      "Iteration 7: loss=2.301845434720002\n",
      "Iteration 8: loss=2.301795424763227\n",
      "Iteration 9: loss=2.3017409570387874\n",
      "Iteration 10: loss=2.3016815158269557\n",
      "Iteration 11: loss=2.3016165106567663\n",
      "Iteration 12: loss=2.3015452919335244\n",
      "Iteration 13: loss=2.3014670854718147\n",
      "Iteration 14: loss=2.301381024268615\n",
      "Iteration 15: loss=2.30128609583826\n",
      "Iteration 16: loss=2.301181144675395\n",
      "Iteration 17: loss=2.3010648484307934\n",
      "Iteration 18: loss=2.3009356168727986\n",
      "Iteration 19: loss=2.3007915922327524\n",
      "Iteration 20: loss=2.300630650776509\n",
      "Iteration 21: loss=2.300450226039728\n",
      "Iteration 22: loss=2.300247307733741\n",
      "Iteration 23: loss=2.3000182917656335\n",
      "Iteration 24: loss=2.299758926760436\n",
      "Iteration 25: loss=2.299464023071657\n",
      "Iteration 26: loss=2.299127291719946\n",
      "Iteration 27: loss=2.298741190802941\n",
      "Iteration 28: loss=2.29829638082988\n",
      "Iteration 29: loss=2.297781359734363\n",
      "Iteration 30: loss=2.2971818534518134\n",
      "Iteration 31: loss=2.2964800678860344\n",
      "Iteration 32: loss=2.2956534736476657\n",
      "Iteration 33: loss=2.2946734071925956\n",
      "Iteration 34: loss=2.293502961313207\n",
      "Iteration 35: loss=2.292094231608278\n",
      "Iteration 36: loss=2.290384238261664\n",
      "Iteration 37: loss=2.288289407217938\n",
      "Iteration 38: loss=2.285697141154336\n",
      "Iteration 39: loss=2.282453590075982\n",
      "Iteration 40: loss=2.278345301416411\n",
      "Iteration 41: loss=2.2730711472874803\n",
      "Iteration 42: loss=2.2661984598025127\n",
      "Iteration 43: loss=2.2570931699071553\n",
      "Iteration 44: loss=2.2448056580371394\n",
      "Iteration 45: loss=2.2278813706164624\n",
      "Iteration 46: loss=2.204038443097142\n",
      "Iteration 47: loss=2.169613863982443\n",
      "Iteration 48: loss=2.118614400524481\n",
      "Iteration 49: loss=2.0411675047998896\n",
      "Iteration 50: loss=1.9214530604743703\n",
      "Iteration 51: loss=1.7372802844870066\n",
      "Iteration 52: loss=1.4722653815885374\n",
      "Iteration 53: loss=1.16465043791414\n",
      "Iteration 54: loss=0.9343086767426168\n",
      "Iteration 55: loss=0.8212307335249228\n",
      "Iteration 56: loss=0.769244365730233\n",
      "Iteration 57: loss=0.7437276584393345\n",
      "Iteration 58: loss=0.7293851106739382\n",
      "Iteration 59: loss=0.7204357055602342\n",
      "Iteration 60: loss=0.7144120616391243\n",
      "Iteration 61: loss=0.7101244589394968\n",
      "Iteration 62: loss=0.70693946444555\n",
      "Iteration 63: loss=0.7044931386957479\n",
      "Iteration 64: loss=0.7025630065477889\n",
      "Iteration 65: loss=0.7010063135488012\n",
      "Iteration 66: loss=0.6997275550826433\n",
      "Iteration 67: loss=0.6986607279865857\n",
      "Iteration 68: loss=0.6977588083992288\n",
      "Iteration 69: loss=0.6969875609182075\n",
      "Iteration 70: loss=0.6963214682377825\n",
      "Iteration 71: loss=0.6957413636182993\n",
      "Iteration 72: loss=0.695232747234477\n",
      "Iteration 73: loss=0.694785368852115\n",
      "Iteration 74: loss=0.6943937742943957\n",
      "Iteration 75: loss=0.6940617696626854\n",
      "Iteration 76: loss=0.6938162093549034\n",
      "Iteration 77: loss=0.6937513880139468\n",
      "Iteration 78: loss=0.6941766429446842\n",
      "Iteration 79: loss=0.6960600593289111\n",
      "Iteration 80: loss=0.7026530634502711\n",
      "Iteration 81: loss=0.7232275740761751\n",
      "Iteration 82: loss=0.7853961362997011\n",
      "Iteration 83: loss=0.9010749244583641\n",
      "Iteration 84: loss=1.03157494930876\n",
      "Iteration 85: loss=0.8924426115654418\n",
      "Iteration 86: loss=0.8080392567071824\n",
      "Iteration 87: loss=0.7400028047226592\n",
      "Iteration 88: loss=0.7190100165378974\n",
      "Iteration 89: loss=0.7095073931399141\n",
      "Iteration 90: loss=0.7051671045945329\n",
      "Iteration 91: loss=0.7025052365452928\n",
      "Iteration 92: loss=0.7007486825001539\n",
      "Iteration 93: loss=0.6994298871617214\n",
      "Iteration 94: loss=0.698421461276826\n",
      "Iteration 95: loss=0.6976086506081436\n",
      "Iteration 96: loss=0.6969677460831476\n",
      "Iteration 97: loss=0.6964562251115092\n",
      "Iteration 98: loss=0.6960890264332551\n",
      "Iteration 99: loss=0.695853335579059\n",
      "Iteration 100: loss=0.6958132876335124\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, X_train, y_train, lr=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "37cfdb04-ed53-47eb-b2de-dfd861f99324",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.78292938e-01, 5.13304768e-01, 1.05892020e-03, ...,\n",
       "        1.03853368e-03, 1.02085644e-03, 1.05151952e-03],\n",
       "       [4.78206084e-01, 5.12804964e-01, 1.13276386e-03, ...,\n",
       "        1.11115383e-03, 1.09249050e-03, 1.12491555e-03],\n",
       "       [4.78219733e-01, 5.18028951e-01, 4.73275410e-04, ...,\n",
       "        4.62969289e-04, 4.54055328e-04, 4.69522772e-04],\n",
       "       ...,\n",
       "       [4.78486358e-01, 5.15509945e-01, 7.56977951e-04, ...,\n",
       "        7.41584078e-04, 7.28287373e-04, 7.51375433e-04],\n",
       "       [4.78426097e-01, 5.16748756e-01, 6.08554429e-04, ...,\n",
       "        5.95770410e-04, 5.84721668e-04, 6.03898738e-04],\n",
       "       [4.78434699e-01, 5.16652219e-01, 6.19630627e-04, ...,\n",
       "        6.06651783e-04, 5.95425872e-04, 6.14902989e-04]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7d6bc6f2-ed64-4dc8-81a2-f8c0235a3fa6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.453125, 0.546875])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "counts/counts.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1dce8d-d2a9-42c3-a483-22ffeb1e74d9",
   "metadata": {},
   "source": [
    "# test on real dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "843adcf5-78e2-4143-9f64-5617273e510c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load MNIST dataset from torchvision\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='../../data',\n",
    "                                           train = True,\n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='../../data',\n",
    "                                          train = False,\n",
    "                                          transform=transforms.ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0d25ac2-d632-4c3a-b942-f096a3c1e7e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = train_dataset.data.numpy().reshape(train_dataset.data.shape[0],-1)\n",
    "y_train = train_dataset.targets.numpy()\n",
    "\n",
    "x_test = test_dataset.data.numpy().reshape(test_dataset.data.shape[0],-1)\n",
    "y_test = test_dataset.targets.numpy()\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6562123-a540-499d-8949-10e93c0b6b2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = np.isin(y_train, [0,1,2])\n",
    "x_train = x_train[idx][:10000]\n",
    "y_train = y_train[idx][:10000]\n",
    "\n",
    "idx = np.isin(y_test, [0,1,2])\n",
    "x_test = x_test[idx]\n",
    "y_test = y_test[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4268789a-68ad-4fd1-99a0-7bee04d6e3b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_labels = 10\n",
    "layers = ['relu', 'relu', 'softmax']\n",
    "weights = [np.random.uniform(-0.01, 0.01, (784,64)), np.random.uniform(-0.01, 0.01, (64,16)), np.random.uniform(-0.01, 0.01, (16,10))]\n",
    "\n",
    "model = DNN(n_labels, layers, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be9e90a8-feb3-47df-abfd-cc8225e094bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3162, 0.3677, 0.3161])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "counts/counts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "536c65b2-5049-4068-9cbf-e477d290f0db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: loss=2.2828654064214384\n",
      "Iteration 2: loss=2.266753305613649\n",
      "Iteration 3: loss=2.235204747052911\n",
      "Iteration 4: loss=2.164515117377543\n",
      "Iteration 5: loss=1.9833774765770236\n",
      "Iteration 6: loss=1.5382367749367698\n",
      "Iteration 7: loss=1.0890469132298424\n",
      "Iteration 8: loss=1.0696233318949682\n",
      "Iteration 9: loss=2.2422211241312193\n",
      "Iteration 10: loss=1.5807183686429112\n",
      "Iteration 11: loss=1.227329649688043\n",
      "Iteration 12: loss=1.0345105793229221\n",
      "Iteration 13: loss=1.021437762125589\n",
      "Iteration 14: loss=0.8858952033305468\n",
      "Iteration 15: loss=1.0148063734581358\n",
      "Iteration 16: loss=0.6835801545047403\n",
      "Iteration 17: loss=0.7000682874515882\n",
      "Iteration 18: loss=0.7316884581180361\n",
      "Iteration 19: loss=0.8088265573893504\n",
      "Iteration 20: loss=0.5922964525410027\n",
      "Iteration 21: loss=0.5660081459195099\n",
      "Iteration 22: loss=0.5741177365559067\n",
      "Iteration 23: loss=0.6969263019849808\n",
      "Iteration 24: loss=0.7014367701590752\n",
      "Iteration 25: loss=0.6605993298558682\n",
      "Iteration 26: loss=0.5046746125192446\n",
      "Iteration 27: loss=0.5294152403908041\n",
      "Iteration 28: loss=0.6394930869187361\n",
      "Iteration 29: loss=0.7216284766357177\n",
      "Iteration 30: loss=0.5375672394834421\n",
      "Iteration 31: loss=0.47149530045068133\n",
      "Iteration 32: loss=0.42926998064825783\n",
      "Iteration 33: loss=0.4271213113286919\n",
      "Iteration 34: loss=0.5615144625737492\n",
      "Iteration 35: loss=0.7577691075816377\n",
      "Iteration 36: loss=0.5202349509110666\n",
      "Iteration 37: loss=0.3573358904856224\n",
      "Iteration 38: loss=0.21288439159089198\n",
      "Iteration 39: loss=0.16179327283018374\n",
      "Iteration 40: loss=0.13473195262548862\n",
      "Iteration 41: loss=0.12136278993953122\n",
      "Iteration 42: loss=0.11258446295752624\n",
      "Iteration 43: loss=0.10619071387529976\n",
      "Iteration 44: loss=0.1011228576537232\n",
      "Iteration 45: loss=0.09696898731590635\n",
      "Iteration 46: loss=0.09346216128595822\n",
      "Iteration 47: loss=0.09042478080228207\n",
      "Iteration 48: loss=0.08774218629010824\n",
      "Iteration 49: loss=0.08534026031171621\n",
      "Iteration 50: loss=0.08315139751351924\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, x_train, y_train, lr=1e-2, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b95a31b-35f4-499e-b16a-b8c6b73da75d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.984429615506832"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(x_test).argmax(axis=1) == y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22dd3c31-eb93-4b92-933d-6114ccab19cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, ..., 0, 1, 2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b5e85d-a7e4-487e-8007-fea7697f8c33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3385cc89-6240-4887-a8f2-1ac994fdb414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
