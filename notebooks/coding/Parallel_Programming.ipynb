{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "759d285e-b318-4e95-9a4b-dd0ce1737ede",
   "metadata": {},
   "source": [
    "# [Multithreading vs multiprocessing vs acyncio in Python](https://www.linkedin.com/pulse/multithreading-vs-multiprocessing-asyncio-code-examples-kaushik-yxgjc/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2a6675-5fdd-4300-8017-f7a63f867044",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"png/python_parallel.png\" width=800 height=400>\n",
    "<img src=\"png/parallel_methods.png\" width=800 height=400>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adb04ca-87c2-43d2-bc06-54c4cb51c765",
   "metadata": {},
   "source": [
    "Multithreading uses threads in a single process, multiprocessing spawns separate processes while asyncio leverages an event loop and coroutines for cooperative multitasking.\n",
    "\n",
    "> Use multithreading when you need to run I/O bound or CPU bound jobs concurrently in a single process. Examples - serving concurrent requests in a web server, parallel processing in data science apps etc.\n",
    "\n",
    "> Leverage multiprocessing for CPU bound jobs that require truly parallel execution across multiple cores. Examples - multimedia processing, scientific computations etc.\n",
    "\n",
    "> Asyncio suits network applications like web servers, databases etc. where blocking I/O operations limit performance. Asyncio minimizes blocking for high throughput.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bea86a7c-5157-4ef5-9349-8a8446d87134",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cpu :  10\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "print(\"Number of cpu : \", multiprocessing.cpu_count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594e1c24-21b2-48b2-8e2d-c329bd46badd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multithreading vs multiprocessing\n",
    "\n",
    "> Multithreading refers to concurrently executing multiple threads within a single process. \n",
    "\n",
    "> Multiprocessing refers to executing multiple processes concurrently.\n",
    "\n",
    "> The key advantage of multithreading is that it allows maximum utilization of a single CPU core by executing threads concurrently. All threads share same process resources like memory. Context switching between threads is lightweight.\n",
    "\n",
    "> However, multithreading also comes with challenges like race conditions, deadlocks etc. when multiple threads try to access shared resources. Careful synchronization is needed to avoid these issues.\n",
    "\n",
    "> Multiprocessing avoids GIL limitations and allows full utilization of multicore CPUs. But processes have higher memory overhead compared to threads. Interprocess communication is more complicated compared to thread synchronization primitives.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99413a58-db53-4fee-a727-056583f6481c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Multiprocessing examples\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8623301c-a7bb-47b9-9484-c80390385be1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n",
      "--- 123.82402896881104 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from multiprocess import Pool\n",
    "import time\n",
    "import random\n",
    "\n",
    "def cal_square(x: int=0)->int:\n",
    "    time.sleep(random.random()*(1000-x)/200)\n",
    "    return x**2\n",
    "\n",
    "start_time = time.time()\n",
    "p = Pool()\n",
    "res = p.map(cal_square, [i for i in range(1000)])\n",
    "p.close()\n",
    "p.join()\n",
    "print(res[:10])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82850a34-dd62-46d5-8b0b-414114b399cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1681, 81, 2500, 2025, 484, 225, 1444, 1369, 0, 1225]\n",
      "--- 25.077701807022095 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# asynchronus multiprocessing\n",
    "\n",
    "def add_to_res(x: int):\n",
    "    res.append(x)\n",
    "start_time = time.time()\n",
    "p = Pool(50)\n",
    "res = []\n",
    "for i in range(1000):\n",
    "    p.apply_async(cal_square, args=(i,), callback=add_to_res)\n",
    "p.close()\n",
    "p.join()\n",
    "print(res[:10])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9281b71d-78d9-4d19-ae49-711f0be2d3ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use multiprocessing to parse urls\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_urls(url):\n",
    "    reqs = requests.get(url)\n",
    "    soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "\n",
    "    urls = []\n",
    "    for link in soup.find_all('a'):\n",
    "        urls.append(link.get('href'))\n",
    "    return urls\n",
    "\n",
    "def get_all_urls(url, max_urls=10000):\n",
    "    '''\n",
    "        Serial method to get all urls\n",
    "    '''\n",
    "    q = [url]\n",
    "    p = 0\n",
    "    visited = {url: True}\n",
    "    while p < len(q) and len(q) < max_urls:\n",
    "        x = q[p]\n",
    "        for y in get_urls(x):\n",
    "            if y is not None and y.startswith('https://') and y.split('//')[1].startswith('www'):\n",
    "                if y.split('/')[-1].startswith('?ref'):\n",
    "                    y = '/'.join(y.split('/')[:-1])\n",
    "                if not y.split('/')[-1].startswith('#') and y not in visited:\n",
    "                    q.append(y)\n",
    "                    visited[y] = True\n",
    "        p += 1\n",
    "    return q\n",
    "    \n",
    "\n",
    "def get_all_urls_parallel(url, max_urls=10000, max_worker = 10):\n",
    "    '''\n",
    "        Using multiprocessing to parallel get all urls\n",
    "    '''\n",
    "    def post_process(result):\n",
    "        for y in result:\n",
    "            if y not in visited:\n",
    "                q.append(y)\n",
    "                visited[y] = True\n",
    "                \n",
    "    q = [url]\n",
    "    p = 0\n",
    "    visited = {url: True}\n",
    "    while p < len(q) and len(q) < max_urls:\n",
    "        p_next = min([len(q), p + max_worker])\n",
    "        pool = Pool(max_worker)\n",
    "        for i in range(p, p_next):\n",
    "            pool_res = pool.apply_async(get_urls, args=(q[i],), callback=post_process)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        p = p_next\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4de3fd7c-aa02-4dc8-abab-732586c648dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.396723985672\n",
      "20018 https://www.geeksforgeeks.org/angular-cheat-sheet-a-basic-guide-to-angular\n"
     ]
    }
   ],
   "source": [
    "# Serial method test\n",
    "start_time = time.time()\n",
    "res = get_all_urls('https://www.geeksforgeeks.org/', max_urls=20000)\n",
    "print(time.time() - start_time)\n",
    "print(len(res), res[432])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a81ace3-f824-488c-9aec-f0ea59c53d9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.672960996627808\n",
      "20004 https://www.geeksforgeeks.org/logarithms/?ref=outind\n"
     ]
    }
   ],
   "source": [
    "# parallel method test\n",
    "start_time = time.time()\n",
    "res = get_all_urls_parallel('https://www.geeksforgeeks.org/', max_urls=20000)\n",
    "print(time.time() - start_time)\n",
    "print(len(res), res[432])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46e643a0-16c3-4d77-8f06-3fd5ec4d9a4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2906820774078369 0.03322482109069824 0.0005812644958496094\n"
     ]
    }
   ],
   "source": [
    "# understanding bottleneck\n",
    "url = 'https://www.geeksforgeeks.org/'\n",
    "s1 = time.time()\n",
    "reqs = requests.get(url)\n",
    "s2 = time.time()\n",
    "soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "s3 = time.time()\n",
    "q = []\n",
    "for link in soup.find_all('a'):\n",
    "    y = link.get('href')\n",
    "    if y is not None and y.startswith('https://') and y.split('//')[1].startswith('www') and (not y.split('/')[-1].startswith('#')):\n",
    "        q.append(y)\n",
    "s4 = time.time()\n",
    "print(s2-s1, s3-s2, s4-s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209fdb74-bebb-4366-b14e-924386ca9a6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Async IO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f957c783-347f-43be-980b-869dd05a9b70",
   "metadata": {},
   "source": [
    "> Asyncio provides a single-threaded, non-blocking concurrency model in Python. It uses cooperative multitasking and an event loop to execute coroutines concurrently.\n",
    "\n",
    "> Asyncio is best suited for IO-bound tasks and use cases where execution consists of waiting on network responses, database queries etc. It provides high throughput and minimizes blocking.\n",
    "However, asyncio doesn't allow true parallellism on multicore systems. CPU-bound processing may suffer performance issues. It has a steep learning curve compared to threads and processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e41b7f8-643f-4916-ba5c-37d4ca91af5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.00 seconds.\n",
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225, 256, 289, 324, 361, 400, 441, 484, 529, 576, 625, 676, 729, 784, 841, 900, 961, 1024, 1089, 1156, 1225, 1296, 1369, 1444, 1521, 1600, 1681, 1764, 1849, 1936, 2025, 2116, 2209, 2304, 2401, 2500, 2601, 2704, 2809, 2916, 3025, 3136, 3249, 3364, 3481, 3600, 3721, 3844, 3969, 4096, 4225, 4356, 4489, 4624, 4761, 4900, 5041, 5184, 5329, 5476, 5625, 5776, 5929, 6084, 6241, 6400, 6561, 6724, 6889, 7056, 7225, 7396, 7569, 7744, 7921, 8100, 8281, 8464, 8649, 8836, 9025, 9216, 9409, 9604, 9801]\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import random\n",
    "\n",
    "async def cal_square(x: int):\n",
    "    await asyncio.sleep(random.random())\n",
    "    return x**2\n",
    "\n",
    "async def main():\n",
    "    return await asyncio.gather(*[cal_square(i) for i in range(100)])\n",
    "\n",
    "\n",
    "import time\n",
    "s = time.time()\n",
    "res = await main()\n",
    "elapsed = time.time() - s\n",
    "print(f\"{elapsed:0.2f} seconds.\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c68583c-1acd-4380-a5d0-0e88e880052d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The main time used in prasing urls is to visit the url. \n",
    "# Hence we prefer to use asyncio for parallel to avoid overhead communications between multiple processes.\n",
    "import asyncio\n",
    "import concurrent.futures\n",
    "import requests\n",
    "\n",
    "import asyncio, time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "async def get_urls_asyncio(url, max_urls=10000):\n",
    "    async def get_urls(urls, max_workers=20):\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            loop = asyncio.get_event_loop()\n",
    "            futures = [\n",
    "                loop.run_in_executor(\n",
    "                    executor, \n",
    "                    requests.get, \n",
    "                    url\n",
    "                )\n",
    "                for url in urls\n",
    "            ]\n",
    "        soups = []\n",
    "        for reqs in await asyncio.gather(*futures):\n",
    "            soups.append(BeautifulSoup(reqs.text, 'html.parser'))\n",
    "        return soups\n",
    "                  \n",
    "    q = [url]\n",
    "    visited = {url: True}\n",
    "    p = 0\n",
    "    while p < len(q) and len(q) < max_urls:\n",
    "        p_next = len(q)\n",
    "        soups = await get_urls(q[p:])\n",
    "        for s in soups:\n",
    "            for link in s.find_all('a'):\n",
    "                y = link.get('href')\n",
    "                if y is not None and y.startswith('https://') and y.split('//')[1].startswith('www') and (not y.split('/')[-1].startswith('#')):\n",
    "                    if y not in visited:\n",
    "                        q.append(y)\n",
    "                        visited[y] = True\n",
    "        p = p_next\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "005d9322-3229-4f7b-bb06-a7d4a7a93bfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.94 seconds.\n",
      "21949 https://www.geeksforgeeks.org/introduction-to-queue-data-structure-and-algorithm-tutorials/?ref=outind\n"
     ]
    }
   ],
   "source": [
    "# test asyncio method\n",
    "s = time.time()\n",
    "res = await get_urls_asyncio('https://www.geeksforgeeks.org/')\n",
    "elapsed = time.time() - s\n",
    "print(f\"{elapsed:0.2f} seconds.\")\n",
    "print(len(res), res[432])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a29a5a-b551-445e-bb5f-e9cd4844ea75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f063fc6-8be2-4cd5-851b-9274605bc932",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
